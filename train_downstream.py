import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
import os
import pickle
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, TensorDataset
from model_engine import NicheformerEngine  # å¤ç”¨ä½ ç°åœ¨çš„å¼•æ“æ¥æå–ç‰¹å¾

# ================= é…ç½® =================
# H5AD æ–‡ä»¶ä¸­å­˜å‚¨çœŸå®æ ‡ç­¾çš„åˆ—å (è¯·æ ¹æ®ä½ çš„æ•°æ®ä¿®æ”¹!)
CELL_TYPE_COL = "cell_type"  
REGION_COL = "clust_annot"        # å¦‚æœæ²¡æœ‰åŒºåŸŸæ ‡ç­¾ï¼Œå¯ä»¥è®¾ä¸º None

# è®­ç»ƒå‚æ•°
BATCH_SIZE = 64
EPOCHS = 50
LR = 0.001
# =======================================

class ClassifierHead(nn.Module):
    def __init__(self, input_dim=256, num_classes=10):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        return self.net(x)

def train_classifier(features, labels, save_name, device):
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒåˆ†ç±»å™¨: {save_name}")
    
    # 1. æ ‡ç­¾ç¼–ç  (String -> Int)
    le = LabelEncoder()
    targets = le.fit_transform(labels)
    num_classes = len(le.classes_)
    print(f"æ£€æµ‹åˆ° {num_classes} ä¸ªç±»åˆ«: {le.classes_[:num_classes+1]}...")
    
    # ä¿å­˜ LabelEncoder (æ¨ç†æ—¶è¦æŠŠ Int è½¬å› String)
    with open(f"{save_name}_labels.pkl", "wb") as f:
        pickle.dump(le.classes_.tolist(), f)
    
    # 2. å‡†å¤‡æ•°æ®
    X_train, X_val, y_train, y_val = train_test_split(features, targets, test_size=0.2, random_state=42)
    
    train_ds = TensorDataset(torch.tensor(X_train).float(), torch.tensor(y_train).long())
    val_ds = TensorDataset(torch.tensor(X_val).float(), torch.tensor(y_val).long())
    
    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)
    
    # 3. åˆå§‹åŒ–æ¨¡å‹
    model = ClassifierHead(input_dim=256, num_classes=num_classes).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LR)
    
    # 4. è®­ç»ƒå¾ªç¯
    best_acc = 0.0
    for epoch in range(EPOCHS):
        model.train()
        for X_batch, y_batch in train_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            optimizer.zero_grad()
            outputs = model(X_batch)
            loss = criterion(outputs, y_batch)
            loss.backward()
            optimizer.step()
            
        # éªŒè¯
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for X_batch, y_batch in val_loader:
                X_batch, y_batch = X_batch.to(device), y_batch.to(device)
                outputs = model(X_batch)
                _, predicted = torch.max(outputs.data, 1)
                total += y_batch.size(0)
                correct += (predicted == y_batch).sum().item()
        
        acc = 100 * correct / total
        if epoch % 10 == 0:
            print(f"Epoch {epoch}: Val Acc = {acc:.2f}%")
            
        if acc > best_acc:
            best_acc = acc
            torch.save(model.state_dict(), f"{save_name}.pth")
            
    print(f"âœ… è®­ç»ƒå®Œæˆã€‚æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%ã€‚æ¨¡å‹å·²ä¿å­˜è‡³ {save_name}.pth")

def main():
    # 1. åˆå§‹åŒ–å¼•æ“å¹¶åŠ è½½æ•°æ®
    engine = NicheformerEngine()
    engine.load_data("train.h5ad") # è¯·æ”¹ä¸ºä½ çš„æ–‡ä»¶å
    engine.build_spatial_graph()
    engine.load_model("nicheformer_weights.pth") # ç¡®ä¿è¿™ä¸ªæ–‡ä»¶å­˜åœ¨
    
    # 2. è·å–/è®¡ç®— Embeddings (è¿™æ˜¯æœ€é‡è¦çš„ç‰¹å¾)
    # å¦‚æœå·²æœ‰ç¼“å­˜ä¼šè‡ªåŠ¨åŠ è½½ï¼Œæ²¡æœ‰ä¼šè®¡ç®—
    engine._precompute_embeddings() 
    embeddings = engine.embeddings_cache
    
    if CELL_TYPE_COL in engine.adata.obs:
        print(f"\næ­£åœ¨å¤„ç†ç»†èƒç±»å‹æ•°æ® ({CELL_TYPE_COL})...")
        
        # å®šä¹‰ä¸éœ€è¦çš„åƒåœ¾æ ‡ç­¾åˆ—è¡¨ (æ ¹æ®ä½ çš„è§‚å¯Ÿæ·»åŠ )
        INVALID_LABELS = ['cell', 'Unknown', 'nan', 'N/A']
        
        # è·å–åŸå§‹æ ‡ç­¾åˆ—
        raw_labels = engine.adata.obs[CELL_TYPE_COL].astype(str)
        
        # æ„å»ºè¿‡æ»¤æ©ç ï¼šæ—¢ä¸æ˜¯ NaNï¼Œä¹Ÿä¸åœ¨åƒåœ¾åˆ—è¡¨ä¸­
        # ~ è¡¨ç¤ºâ€œéâ€ï¼Œisin è¡¨ç¤ºâ€œåœ¨åˆ—è¡¨ä¸­â€
        valid_mask = (engine.adata.obs[CELL_TYPE_COL].notna()) & \
                     (~raw_labels.isin(INVALID_LABELS))
        
        # ç»Ÿè®¡ä¸€ä¸‹è¿‡æ»¤äº†å¤šå°‘
        n_total = len(raw_labels)
        n_keep = valid_mask.sum()
        print(f"åŸå§‹ç»†èƒæ•°: {n_total}, è¿‡æ»¤å: {n_keep} (å‰”é™¤äº† {n_total - n_keep} ä¸ªæ¨¡ç³Šç»†èƒ)")

        if n_keep > 0:
            features = embeddings[valid_mask]
            labels = raw_labels[valid_mask].values
            
            train_classifier(features, labels, "cell_type_model", engine.device)
        else:
            print("é”™è¯¯: è¿‡æ»¤åæ²¡æœ‰å‰©ä½™ç»†èƒï¼Œè¯·æ£€æŸ¥è¿‡æ»¤æ¡ä»¶ï¼")

    # 4. è®­ç»ƒåŒºåŸŸåˆ†å‰²åˆ†ç±»å™¨
    if REGION_COL and REGION_COL in engine.adata.obs:
        print("\næ­£åœ¨å‡†å¤‡åŒºåŸŸæ•°æ®...")
        valid_mask = engine.adata.obs[REGION_COL].notna()
        features = embeddings[valid_mask]
        labels = engine.adata.obs[REGION_COL][valid_mask].values.astype(str)
        
        train_classifier(features, labels, "region_model", engine.device)
    else:
        print(f"âš ï¸ è·³è¿‡åŒºåŸŸåˆ†å‰²è®­ç»ƒ (åˆ— '{REGION_COL}' ä¸å­˜åœ¨)ã€‚")

if __name__ == "__main__":
    main()