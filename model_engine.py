import torch
import numpy as np
import scanpy as sc
import pandas as pd
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import sys
import os
import importlib.util
from tqdm import tqdm  # ç”¨äºæ˜¾ç¤ºè¿›åº¦æ¡
import torch
import torch.nn as nn # æ–°å¢å¼•ç”¨
import pickle         # æ–°å¢å¼•ç”¨

current_dir = os.path.dirname(os.path.abspath(__file__))
nicheformer_root = os.path.join(current_dir, "Nicheformer")
possible_paths = [
    os.path.join(nicheformer_root, "src"),
    nicheformer_root,
    os.path.join(current_dir, "nicheformer"),
]
found_path = None
for path in possible_paths:
    if os.path.isdir(os.path.join(path, "nicheformer")):
        found_path = path
        break
if found_path and found_path not in sys.path:
    sys.path.append(found_path)

# å¯¼å…¥æ¨¡å‹ç±»
Nicheformer = None
try:
    from nicheformer.models._nicheformer import Nicheformer
    print("âœ… æˆåŠŸå¯¼å…¥ Nicheformer ç±»")
except ImportError:
    try:
        from nicheformer.models import Nicheformer
        print("âœ… æˆåŠŸå¯¼å…¥ Nicheformer ç±» (from models)")
    except ImportError:
        print("âŒ æ— æ³•å¯¼å…¥ Nicheformerï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚")
class ClassifierHead(nn.Module):
    def __init__(self, input_dim=256, num_classes=10):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, num_classes)
        )
    def forward(self, x): return self.net(x)
# Nicheformer æ¨ç†å¼•æ“
class NicheformerEngine:
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.adata = None
        self.model = None
        self.gene_list = []
        self.gene_to_id = {}
        self.coords = None
        self.kd_tree = None
        self.center = None
        # æ–°å¢ï¼šåˆ†ç±»å™¨æ¨¡å‹å®¹å™¨
        self.cls_model = None
        self.cls_labels = []
        
        self.seg_model = None
        self.seg_labels = []
        # --- è¶…å‚æ•° (å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´) ---
        self.n_neighbors = 20    # é‚»åŸŸå¤§å°
        self.context_length = 1024 # ä¸Šä¸‹æ–‡é•¿åº¦
        self.batch_size = 16     # æ¨ç†æ—¶çš„ Batch Size (æ ¹æ®æ˜¾å­˜è°ƒæ•´)
        self.adata_emb = None  # ç”¨äºå­˜å‚¨é‚»å±…å›¾çš„æŒä¹…åŒ–å¯¹è±¡
        self.pca_cache = None
        # --- ç¼“å­˜ ---
        self.embeddings_cache = None # å­˜å‚¨æ‰€æœ‰ç»†èƒçš„ Latent Vector
        self.cell_type_cache = None
        self.region_cache = None
        self.adata_cache = None # ä¸“é—¨ç”¨äºå­˜å‚¨ Embedding åˆ†æç»“æœçš„ AnnData å¯¹è±¡

    def load_data(self, h5ad_path):
        print(f"Loading data from {h5ad_path}...")
        self.adata = sc.read_h5ad(h5ad_path)
        
        # 1. åŠ è½½å›ºå®šè¯è¡¨
        if os.path.exists("gene_vocab.npy"):
            print("âœ… Found gene_vocab.npy, loading fixed vocabulary...")
            self.gene_list = np.load("gene_vocab.npy", allow_pickle=True).tolist()
        else:
            self.gene_list = self.adata.var_names.tolist()

        # 2. ã€ä¿®å¤ã€‘ç¡¬ç¼–ç åç§»é‡
        # æˆ‘ä»¬å·²ç»é€šè¿‡ä¹‹å‰çš„æµ‹è¯•ç¡®è®¤äº†ï¼šæ¨¡å‹æƒé‡(382) - åŸºå› æ•°(374) = 8
        start_idx = 8
        print(f"âœ… Using fixed Offset (Start Index): {start_idx}")

        # 3. å»ºç«‹æ˜ å°„
        self.gene_to_id = {name: i + start_idx for i, name in enumerate(self.gene_list)}
        
        # éªŒè¯ç¬¬ä¸€ä¸ªåŸºå› 
        print(f"ğŸ” Mapping check: '{self.gene_list[0]}' -> ID {self.gene_to_id[self.gene_list[0]]}")
        print(f"Data loaded. Cells: {self.adata.n_obs}, Genes: {self.adata.n_vars}")

    # ------------------------------------------------------------------

    def build_spatial_graph(self):
        """æ„å»º KDTree ç”¨äºæŸ¥æ‰¾é‚»å±…"""
        if self.coords is None: return
        print("Building spatial neighbor graph (KDTree)...")
        self.kd_tree = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm='ball_tree')
        self.kd_tree.fit(self.coords)
        # é¢„å…ˆè®¡ç®—æ‰€æœ‰ç»†èƒçš„é‚»å±…ç´¢å¼•ï¼ŒåŠ é€Ÿåç»­æ¨ç†
        print("Pre-calculating neighbors for all cells...")
        self.distances, self.neighbor_indices = self.kd_tree.kneighbors(self.coords)
        print("Spatial graph ready.")

    def load_model(self, model_path):
        """åŠ è½½è®­ç»ƒå¥½çš„æƒé‡"""
        if Nicheformer is None: return

        print(f"Loading Nicheformer weights from {model_path}...")
        
        # 1. å®ä¾‹åŒ–æ¨¡å‹ (å‚æ•°å¿…é¡»ä¸ train_nicheformer.py ä¸­ä¸€è‡´)
        self.model = Nicheformer(
            dim_model=256,
            nheads=8,
            dim_feedforward=1024, # 256 * 4
            nlayers=6,
            dropout=0.1,
            batch_first=True,
            masking_p=0.0, # æ¨ç†æ—¶ä¸éœ€è¦ Mask
            n_tokens=len(self.gene_list) + 3,
            context_length=self.context_length,
            lr=1e-4,
            warmup=100,
            batch_size=self.batch_size,
            max_epochs=5,
            learnable_pe=True
        )
        
        # 2. åŠ è½½æƒé‡
        try:
            state_dict = torch.load(model_path, map_location=self.device)
            # å¤„ç†å¯èƒ½çš„ key ä¸åŒ¹é… (ä¾‹å¦‚ lightning ç•™ä¸‹çš„ 'model.' å‰ç¼€)
            new_state_dict = {}
            for k, v in state_dict.items():
                if k.startswith("model."):
                    new_state_dict[k[6:]] = v
                else:
                    new_state_dict[k] = v
            
            self.model.load_state_dict(new_state_dict, strict=False)
            self.model.to(self.device)
            self.model.eval()
            print("âœ… Model loaded successfully.")
            
            # 3. åŠ è½½åç«‹å³è®¡ç®— Embeddings ç¼“å­˜
            self._precompute_embeddings()
            
        except Exception as e:
            print(f"âŒ Error loading weights: {e}")

    def get_coordinates(self):
        """è¿”å›ç»™ Unity çš„åæ ‡"""
        if self.coords is None: return []
        z = np.zeros((self.coords.shape[0], 1))
        return np.hstack([self.coords, z])

    # æ ¸å¿ƒå·¥å…·ï¼šæ„é€ æ¨¡å‹è¾“å…¥ (Batch Tokenization)
    def _get_batch_tokens(self, cell_indices_batch):
        """
        å°†ä¸€æ‰¹ç»†èƒç´¢å¼•è½¬æ¢ä¸º Nicheformer çš„è¾“å…¥ Tensorã€‚
        [ä¿®å¤ç‰ˆ]ï¼šè‡ªåŠ¨æ£€æµ‹æ•°æ®ä½ç½® (.layers['counts'] æˆ– .X)
        """
        batch_tokens = []
        batch_masks = []
        
        # è·å–è¿™æ‰¹ç»†èƒçš„æ‰€æœ‰é‚»å±…ç´¢å¼•
        batch_neighbor_indices = self.neighbor_indices[cell_indices_batch]
        
        # --- ã€ä¿®å¤æ ¸å¿ƒã€‘ç¡®å®šæ•°æ®æº ---
        # ä¼˜å…ˆä½¿ç”¨ counts å±‚ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ X
        if 'counts' in self.adata.layers:
            source_data = self.adata.layers['counts']
        else:
            source_data = self.adata.X

        for i in range(len(cell_indices_batch)):
            neighbors = batch_neighbor_indices[i]
            
            # èšåˆé‚»åŸŸè¡¨è¾¾é‡ (Sum)
            # å¤„ç†ç¨€ç–çŸ©é˜µä¸å¯†é›†çŸ©é˜µçš„å·®å¼‚
            local_expr = source_data[neighbors].sum(axis=0)
            
            # ç¡®ä¿è½¬æ¢ä¸º 1ç»´ numpy æ•°ç»„
            if hasattr(local_expr, "A1"): # matrix
                local_expr = local_expr.A1
            elif hasattr(local_expr, "toarray"): # sparse matrix
                local_expr = local_expr.toarray().flatten()
            else: # numpy array
                local_expr = np.array(local_expr).flatten()
            
            # æå– Top K åŸºå›  -> Tokens
            expressed_indices = np.where(local_expr > 0)[0]
            
            if len(expressed_indices) > self.context_length:
                # æŒ‰è¡¨è¾¾é‡æ’åºå– Top K
                top_k_args = np.argsort(local_expr[expressed_indices])[-self.context_length:]
                selected_indices = expressed_indices[top_k_args]
            else:
                selected_indices = expressed_indices
            
            # æ˜ å°„ä¸º Token ID (Gene ID + 3)
            token_ids = selected_indices + 3
            
            # Padding
            padding_len = self.context_length - len(token_ids)
            if padding_len > 0:
                padded_tokens = np.pad(token_ids, (0, padding_len), 'constant', constant_values=1) # 1=PAD
                # Attention Mask: 0=Keep, 1=Ignore
                att_mask = np.concatenate([np.zeros(len(token_ids)), np.ones(padding_len)])
            else:
                padded_tokens = token_ids
                att_mask = np.zeros(self.context_length)
                
            batch_tokens.append(padded_tokens)
            batch_masks.append(att_mask)
            
        return (torch.tensor(np.array(batch_tokens), dtype=torch.long).to(self.device),
                torch.tensor(np.array(batch_masks), dtype=torch.bool).to(self.device))

    # ==========================================================================
    # é¢„è®¡ç®— Embeddings
    # ==========================================================================
    def _precompute_embeddings(self):
        """
        [ä¼˜åŒ–ç‰ˆ] è®¡ç®—æˆ–åŠ è½½ Embeddings
        å¦‚æœæœ¬åœ°æœ‰ç¼“å­˜æ–‡ä»¶ï¼Œç›´æ¥åŠ è½½ï¼›å¦åˆ™è®¡ç®—å¹¶ä¿å­˜ã€‚
        """
        # å®šä¹‰ç¼“å­˜æ–‡ä»¶å (åŸºäº h5ad æ–‡ä»¶åï¼Œé˜²æ­¢æ··æ·†)
        cache_filename = "embeddings_cache.npy"
        cache_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), cache_filename)

        # 1. å°è¯•ç›´æ¥åŠ è½½
        if os.path.exists(cache_path):
            print(f"[Cache] Found cached embeddings at {cache_filename}, loading...")
            try:
                self.embeddings_cache = np.load(cache_path)
                # ç®€å•çš„æ ¡éªŒ
                if self.embeddings_cache.shape[0] == self.adata.n_obs:
                    print(f"[Cache] Successfully loaded embeddings. Shape: {self.embeddings_cache.shape}")
                    return
                else:
                    print("[Cache] Cached embeddings shape mismatch. Recomputing...")
            except Exception as e:
                print(f"[Cache] Error loading cache: {e}. Recomputing...")

        # 2. å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œåˆ™å¼€å§‹è®¡ç®— (åŸé€»è¾‘)
        print("Computing embeddings for all cells (First time run)...")
        self.embeddings_cache = []
        n_cells = self.adata.n_obs
        
        # ç¡®ä¿æ¨¡å‹åœ¨ eval æ¨¡å¼
        self.model.eval()
        
        with torch.no_grad():
            for i in tqdm(range(0, n_cells, self.batch_size), desc="Inference"):
                batch_indices = np.arange(i, min(i + self.batch_size, n_cells))
                x, mask = self._get_batch_tokens(batch_indices)
                output = self.model(x, mask)
                feats = output['transformer_output']
                
                # Mean Pooling
                mask_expanded = mask.unsqueeze(-1).float()
                feats_sum = (feats * (1 - mask_expanded)).sum(dim=1)
                mask_sum = (1 - mask_expanded).sum(dim=1)
                feats_pooled = feats_sum / (mask_sum + 1e-9)
                
                self.embeddings_cache.append(feats_pooled.cpu().numpy())
                
        self.embeddings_cache = np.concatenate(self.embeddings_cache, axis=0)
        print(f"Embeddings computed. Shape: {self.embeddings_cache.shape}")
        
        # 3. ä¿å­˜åˆ°ç¡¬ç›˜
        np.save(cache_path, self.embeddings_cache)
        print(f"[Cache] Embeddings saved to {cache_filename}")

    # ==========================================================================
    # åŠŸèƒ½ 1: åŸºå› æ’è¡¥ / è¡¨è¾¾é‡é¢„æµ‹
    # ==========================================================================
    def predict_gene_expression(self, gene_name):
        """
        [æé€Ÿç‰ˆ] åŸºå› æ’è¡¥
        åŸç†ï¼šä¸å†é‡æ–°è¿è¡Œ Transformerï¼Œè€Œæ˜¯ç›´æ¥åˆ©ç”¨ç¼“å­˜çš„ Embeddings è¿›è¡Œçº¿æ€§æ˜ å°„ã€‚
        æ—¶é—´å¤æ‚åº¦ï¼šä» O(N*L*D^2) é™ä½åˆ° O(N*D)ï¼Œé€Ÿåº¦æå‡ 1000 å€ä»¥ä¸Šã€‚
        """
        # 1. æ£€æŸ¥åŸºå› æ˜¯å¦å­˜åœ¨
        if gene_name not in self.gene_to_id:
            print(f"æ’è¡¥å‡ºé”™: Gene {gene_name} not found.")
            return None
        
        # 2. è·å–ç›®æ ‡åŸºå› çš„ Token ID
        # æ³¨æ„ï¼šGeneformer/Nicheformer é€šå¸¸æœ‰ç‰¹æ®Š Tokenï¼ŒåŸºå›  ID é€šå¸¸è¦åç§» (æ¯”å¦‚ +3)
        # è¿™é‡Œçš„ gene_to_id åº”è¯¥å·²ç»æ˜¯åŒ…å«äº†åç§»é‡çš„ (æˆ‘ä»¬åœ¨ server.py é‡Œæ”¹è¿‡äº†)
        target_token_id = self.gene_to_id[gene_name]
        
        print(f"[Fast-Impute] æ­£åœ¨æé€Ÿæ’è¡¥: {gene_name} (Token ID: {target_token_id})...")

        # 3. æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨
        if self.embeddings_cache is None:
            print("é”™è¯¯: Embeddings å°šæœªè®¡ç®—ï¼Œæ— æ³•ä½¿ç”¨å¿«é€Ÿæ’è¡¥ã€‚è¯·æ£€æŸ¥å¯åŠ¨æµç¨‹ã€‚")
            return None

        # 4. æ‰§è¡ŒçŸ©é˜µä¹˜æ³• (æ ¸å¿ƒä¼˜åŒ–)
        try:
            # -------------------------------------------------------
            # æ­¥éª¤ A: å‡†å¤‡ Embedding (N_cells, 256)
            # -------------------------------------------------------
            # ç¡®ä¿æ˜¯ Tensor æ ¼å¼
            if isinstance(self.embeddings_cache, np.ndarray):
                embeddings = torch.tensor(self.embeddings_cache).to(self.device)
            else:
                embeddings = self.embeddings_cache.to(self.device)

            # -------------------------------------------------------
            # æ­¥éª¤ B: æå–ç‰¹å®šåŸºå› çš„è§£ç æƒé‡ (1, 256)
            # -------------------------------------------------------
            # Nicheformer çš„è§£ç å¤´é€šå¸¸å« classifier_head æˆ– decoder
            # å®ƒçš„æƒé‡å½¢çŠ¶æ˜¯ [Vocab_Size, Hidden_Dim]
            if hasattr(self.model, "classifier_head"):
                decoder_layer = self.model.classifier_head
            elif hasattr(self.model, "decoder"):
                decoder_layer = self.model.decoder
            else:
                # å°è¯•æ ¹æ®å¸¸ç”¨åçŒœæµ‹
                print("è­¦å‘Š: æ— æ³•è‡ªåŠ¨æ‰¾åˆ°è§£ç å±‚ï¼Œå°è¯•ä½¿ç”¨ model.lm_head")
                decoder_layer = self.model.lm_head

            # æˆ‘ä»¬åªéœ€è¦æå–å±äº target_gene çš„é‚£ä¸€åˆ—æƒé‡å’Œåç½®
            # è¿™æ ·é¿å…äº†è®¡ç®—æ‰€æœ‰ 20000 ä¸ªåŸºå› çš„æ¦‚ç‡ï¼ŒèŠ‚çœå¤§é‡æ˜¾å­˜
            
            # æƒé‡: [256]
            target_weight = decoder_layer.weight[target_token_id, :] 
            # åç½®: scalar
            target_bias = decoder_layer.bias[target_token_id]

            # -------------------------------------------------------
            # æ­¥éª¤ C: æé€Ÿè®¡ç®— (Dot Product)
            # [N, 256] @ [256] -> [N]
            # -------------------------------------------------------
            with torch.no_grad():
                # çº¿æ€§æŠ•å½±ï¼š y = xW^T + b
                # embeddings: [26678, 256]
                # target_weight: [256]
                logits = torch.mv(embeddings, target_weight) + target_bias
                
                # å¯é€‰ï¼šSigmoid æˆ– Softmax (å–å†³äºæ¨¡å‹è®­ç»ƒç›®æ ‡ï¼Œé€šå¸¸æ’è¡¥ç”¨ Sigmoid æˆ–ç›´æ¥ Logits)
                # å¦‚æœæ•°å€¼èŒƒå›´å¾ˆå¤§ï¼Œå»ºè®®å½’ä¸€åŒ–ä¸€ä¸‹ä¾›å‰ç«¯å±•ç¤º
                predicted_expression = torch.sigmoid(logits).cpu().numpy()

            print(f"[Fast-Impute] è®¡ç®—å®Œæˆã€‚Min: {predicted_expression.min():.4f}, Max: {predicted_expression.max():.4f}")
            return predicted_expression

        except Exception as e:
            print(f"æé€Ÿæ’è¡¥å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None

    def load_downstream_models(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æœ‰ç›‘ç£åˆ†ç±»å™¨"""
        print("[AI] Loading downstream classifiers...")
        
        # 1. åŠ è½½ç»†èƒç±»å‹æ¨¡å‹
        try:
            if os.path.exists("cell_type_model_labels.pkl"):
                with open("cell_type_model_labels.pkl", "rb") as f:
                    self.cls_labels = pickle.load(f)
                
                self.cls_model = ClassifierHead(num_classes=len(self.cls_labels))
                self.cls_model.load_state_dict(torch.load("cell_type_model.pth", map_location=self.device))
                self.cls_model.to(self.device).eval()
                print(f"âœ… Cell Type Classifier loaded ({len(self.cls_labels)} classes)")
            else:
                print("âš ï¸ No cell type model found. predict_cell_types will fail.")
        except Exception as e:
            print(f"âŒ Error loading cell type model: {e}")

        # 2. åŠ è½½åŒºåŸŸåˆ†å‰²æ¨¡å‹
        try:
            if os.path.exists("region_model_labels.pkl"):
                with open("region_model_labels.pkl", "rb") as f:
                    self.seg_labels = pickle.load(f)
                
                self.seg_model = ClassifierHead(num_classes=len(self.seg_labels))
                self.seg_model.load_state_dict(torch.load("region_model.pth", map_location=self.device))
                self.seg_model.to(self.device).eval()
                print(f"âœ… Region Classifier loaded ({len(self.seg_labels)} regions)")
        except Exception as e:
            print(f"âš ï¸ Region model loading skipped: {e}")

    # ==========================================================================
    # ã€é‡å†™ã€‘åŠŸèƒ½ 2: ç»†èƒç±»å‹æ³¨é‡Š (æœ‰ç›‘ç£)
    # ==========================================================================
    def predict_cell_types(self):
        """
        ä½¿ç”¨è®­ç»ƒå¥½çš„åˆ†ç±»å™¨é¢„æµ‹çœŸå®ç»†èƒåç§°
        """
        if self.cell_type_cache is not None:
            return self.cell_type_cache
            
        if self.embeddings_cache is None: self._precompute_embeddings()
        if self.cls_model is None: 
            # å¦‚æœæ²¡æœ‰æ¨¡å‹ï¼Œå°è¯•åŠ è½½ï¼ˆæˆ–è€…å›é€€åˆ° Leiden? å»ºè®®è¿™é‡Œå¼ºåˆ¶è¦æ±‚æ¨¡å‹ï¼‰
            self.load_downstream_models()
            if self.cls_model is None:
                return [], [] # å¤±è´¥è¿”å›ç©º

        print("Predicting cell types using Supervised Classifier...")
        
        # æ‰¹é‡æ¨ç†
        predictions = []
        # å°† embedding è½¬ä¸º Tensor
        features = torch.tensor(self.embeddings_cache).float().to(self.device)
        
        with torch.no_grad():
            # æ˜¾å­˜å¦‚æœä¸å¤Ÿï¼Œè¿™é‡Œä¹Ÿè¦åˆ† Batchï¼Œä½†åªæœ‰ Linear å±‚é€šå¸¸ä¸€æ¬¡èƒ½è·‘å®Œ 2.6w
            outputs = self.cls_model(features)
            _, predicted_ids = torch.max(outputs, 1)
            predictions = predicted_ids.cpu().numpy()
            
        # ç”Ÿæˆå›¾ä¾‹
        # self.cls_labels æ˜¯ ['Astro', 'Micro', 'T-Cell'...]
        legend = []
        import colorsys
        for i, name in enumerate(self.cls_labels):
            hue = i / len(self.cls_labels)
            rgb = colorsys.hsv_to_rgb(hue, 0.8, 0.9)
            hex_color = '#%02x%02x%02x' % (int(rgb[0]*255), int(rgb[1]*255), int(rgb[2]*255))
            legend.append({"id": int(i), "name": name, "color": hex_color})
            
        self.cell_type_cache = (predictions, legend)
        return predictions, legend

    # ==========================================================================
    # ã€é‡å†™ã€‘åŠŸèƒ½ 3: ç»„ç»‡åŒºåŸŸè¯­ä¹‰åˆ†å‰² (æœ‰ç›‘ç£)
    # ==========================================================================
    def segment_tissue_regions(self):
        """
        ä½¿ç”¨è®­ç»ƒå¥½çš„åˆ†ç±»å™¨é¢„æµ‹çœŸå®åŒºåŸŸåç§°
        """
        if self.region_cache is not None: return self.region_cache
        if self.embeddings_cache is None: self._precompute_embeddings()
        if self.seg_model is None: 
            self.load_downstream_models()
            if self.seg_model is None:
                # å›é€€ç­–ç•¥ï¼šå¦‚æœæ²¡æœ‰è®­ç»ƒåŒºåŸŸæ¨¡å‹ï¼Œä½¿ç”¨ KMeans
                print("âš ï¸ No supervised region model found, falling back to KMeans.")
                from sklearn.cluster import KMeans
                kmeans = KMeans(n_clusters=8, random_state=42).fit(self.embeddings_cache)
                return kmeans.labels_, [f"Region_{i}" for i in np.unique(kmeans.labels_)]

        print("Segmenting tissue regions using Supervised Classifier...")
        
        features = torch.tensor(self.embeddings_cache).float().to(self.device)
        with torch.no_grad():
            outputs = self.seg_model(features)
            _, predicted_ids = torch.max(outputs, 1)
            region_ids = predicted_ids.cpu().numpy()
            
        # æ˜ å°„å›åå­—åˆ—è¡¨
        # region_names = ["Cortex", "Thalamus"...]
        region_names = self.seg_labels 
        
        self.region_cache = (region_ids, region_names)
        return region_ids, region_names
   # ==========================================================================
    # é›¶æ ·æœ¬èšç±» (Zero-Shot Clustering) - K-Means ç‰ˆæœ¬
    def run_zero_shot_clustering(self, n_clusters=10):
            """
            [æé€Ÿç‰ˆ - MiniBatchKMeans + PCA Cache] é›¶æ ·æœ¬èšç±»
            é€Ÿåº¦ä¼˜åŒ–ï¼š
            1. ç¼“å­˜ PCA ç»“æœï¼ˆé¿å…é‡å¤é™ç»´ï¼‰
            2. ä½¿ç”¨ MiniBatchKMeansï¼ˆå°æ‰¹é‡è¿­ä»£ï¼Œæ¯”æ ‡å‡† KMeans å¿« 10-50 å€ï¼‰
            """
            # 1. ç¡®ä¿æœ‰ç‰¹å¾
            if self.embeddings_cache is None:
                self._precompute_embeddings()
                
            print(f"[AI] Running Fast Clustering (Target K={n_clusters})...")
            
            # 2. å®‰å…¨é™åˆ¶
            n_clusters = int(n_clusters)
            n_clusters = max(2, n_clusters)
            n_clusters = min(n_clusters, 100)
            
            # 3. å‡†å¤‡æ•°æ® (å« PCA ç¼“å­˜æœºåˆ¶)
            try:
                from sklearn.cluster import MiniBatchKMeans
                from sklearn.decomposition import PCA
                
                # --- PCA ç¼“å­˜é€»è¾‘ ---
                if self.pca_cache is None:
                    print(f"   - [1/2] Computing PCA (First time only)...")
                    # å¦‚æœç»´åº¦ > 50ï¼Œè¿›è¡Œé™ç»´å¹¶ç¼“å­˜
                    if self.embeddings_cache.shape[1] > 50:
                        pca = PCA(n_components=50, random_state=42)
                        self.pca_cache = pca.fit_transform(self.embeddings_cache)
                    else:
                        self.pca_cache = self.embeddings_cache
                    print(f"   - PCA Cached. Shape: {self.pca_cache.shape}")
                else:
                    # print("   - [1/2] Using cached PCA data (Skipping calculation).")
                    pass
                
                # ä½¿ç”¨ç¼“å­˜çš„æ•°æ®
                X_data = self.pca_cache
                
                # --- æé€Ÿèšç±»é€»è¾‘ ---
                # MiniBatchKMeans: ç‰ºç‰²å¾®å°çš„ç²¾åº¦æ¢å–å·¨å¤§çš„é€Ÿåº¦æå‡
                # batch_size: æ¯æ¬¡åªçœ‹ 2048 ä¸ªç»†èƒ
                # n_init: åªå°è¯• 3 æ¬¡ä¸åŒçš„åˆå§‹åŒ– (æ ‡å‡†æ˜¯ 10 æ¬¡)
                kmeans = MiniBatchKMeans(
                    n_clusters=n_clusters, 
                    batch_size=2048, 
                    n_init=3, 
                    random_state=42,
                    reassignment_ratio=0 # é˜²æ­¢æŸäº›ç±»å› ä¸ºå¤ªå°è¢«ä¸¢å¼ƒ
                )
                
                # fit_predict æ¯«ç§’çº§å®Œæˆ
                clusters = kmeans.fit_predict(X_data)
                
                unique_clusters = np.unique(clusters)
                print(f"   - [2/2] Clustering finished. Groups: {len(unique_clusters)}")
                
                # 4. ç”Ÿæˆå›¾ä¾‹ (ä¿æŒä¸å˜)
                legend = []
                import colorsys
                for i, cid in enumerate(unique_clusters):
                    hue = (i * 0.618033988749895) % 1.0 
                    rgb = colorsys.hsv_to_rgb(hue, 0.75, 0.95) 
                    hex_color = '#%02x%02x%02x' % (int(rgb[0]*255), int(rgb[1]*255), int(rgb[2]*255))
                    
                    legend.append({
                        "id": int(cid), 
                        "name": f"Cluster {cid}", 
                        "color": hex_color
                    })
                    
                return clusters, legend

            except Exception as e:
                print(f"âŒ Clustering Error: {e}")
                import traceback
                traceback.print_exc()
                return np.zeros(len(self.embeddings_cache), dtype=int), []